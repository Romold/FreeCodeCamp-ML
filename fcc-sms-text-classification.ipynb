{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:41:14.177972Z","iopub.execute_input":"2024-12-27T04:41:14.178266Z","iopub.status.idle":"2024-12-27T04:41:14.472007Z","shell.execute_reply.started":"2024-12-27T04:41:14.178234Z","shell.execute_reply":"2024-12-27T04:41:14.471147Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# import libraries\ntry:\n  # %tensorflow_version only exists in Colab.\n  !pip install tf-nightly\nexcept Exception:\n  pass\nimport tensorflow as tf\nimport pandas as pd\nfrom tensorflow import keras\n!pip install tensorflow-datasets\nimport tensorflow_datasets as tfds\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:41:14.473006Z","iopub.execute_input":"2024-12-27T04:41:14.473390Z","iopub.status.idle":"2024-12-27T04:42:06.826831Z","shell.execute_reply.started":"2024-12-27T04:41:14.473355Z","shell.execute_reply":"2024-12-27T04:42:06.825793Z"}},"outputs":[{"name":"stdout","text":"Collecting tf-nightly\n  Downloading tf_nightly-2.19.0.dev20241219-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.3.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (24.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (71.0.4)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.64.1)\nCollecting tb-nightly~=2.19.0.a (from tf-nightly)\n  Downloading tb_nightly-2.19.0a20241226-py3-none-any.whl.metadata (1.6 kB)\nCollecting keras-nightly>=3.6.0.dev (from tf-nightly)\n  Downloading keras_nightly-3.7.0.dev2024122703-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.11.0)\nRequirement already satisfied: ml-dtypes<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.44.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (13.8.1)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.12.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly) (3.0.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.19.0.a->tf-nightly) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.6.0.dev->tf-nightly) (0.1.2)\nDownloading tf_nightly-2.19.0.dev20241219-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (634.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.0/634.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras_nightly-3.7.0.dev2024122703-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tb_nightly-2.19.0a20241226-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tb-nightly, keras-nightly, tf-nightly\nSuccessfully installed keras-nightly-3.7.0.dev2024122703 tb-nightly-2.19.0a20241226 tf-nightly-2.19.0.dev20241219\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.6)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.4.0)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.7)\nRequirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\nRequirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.26.4)\nRequirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (3.20.3)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\nRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (18.1.0)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.32.3)\nRequirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.6)\nRequirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.15.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.4.0)\nRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.66.5)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.16.0)\nRequirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.5.1)\nRequirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.9.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (2024.6.1)\nRequirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (6.4.5)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (4.12.2)\nRequirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (3.20.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2024.8.30)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets) (1.16.0)\nRequirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets) (0.16)\n2.19.0-dev20241219\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# get data files\n!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n\ntrain_file_path = \"train-data.tsv\"\ntest_file_path = \"valid-data.tsv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:42:06.828419Z","iopub.execute_input":"2024-12-27T04:42:06.829185Z","iopub.status.idle":"2024-12-27T04:42:07.492836Z","shell.execute_reply.started":"2024-12-27T04:42:06.829161Z","shell.execute_reply":"2024-12-27T04:42:07.492037Z"}},"outputs":[{"name":"stdout","text":"--2024-12-27 04:42:06--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\nResolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.3.33, 104.26.2.33, ...\nConnecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 358233 (350K) [text/tab-separated-values]\nSaving to: ‘train-data.tsv’\n\ntrain-data.tsv      100%[===================>] 349.84K  --.-KB/s    in 0.03s   \n\n2024-12-27 04:42:07 (9.81 MB/s) - ‘train-data.tsv’ saved [358233/358233]\n\n--2024-12-27 04:42:07--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\nResolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 172.67.70.149, 104.26.3.33, ...\nConnecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 118774 (116K) [text/tab-separated-values]\nSaving to: ‘valid-data.tsv’\n\nvalid-data.tsv      100%[===================>] 115.99K  --.-KB/s    in 0.01s   \n\n2024-12-27 04:42:07 (9.76 MB/s) - ‘valid-data.tsv’ saved [118774/118774]\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"names = [\"class\", \"message\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:42:07.494100Z","iopub.execute_input":"2024-12-27T04:42:07.494327Z","iopub.status.idle":"2024-12-27T04:42:07.498004Z","shell.execute_reply.started":"2024-12-27T04:42:07.494308Z","shell.execute_reply":"2024-12-27T04:42:07.497331Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_file = pd.read_csv(train_file_path, sep='\\t', names=names)\ntrain_file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:42:07.498866Z","iopub.execute_input":"2024-12-27T04:42:07.499124Z","iopub.status.idle":"2024-12-27T04:42:07.558573Z","shell.execute_reply.started":"2024-12-27T04:42:07.499093Z","shell.execute_reply":"2024-12-27T04:42:07.557964Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     class                                            message\n0      ham  ahhhh...just woken up!had a bad dream about u ...\n1      ham                           you can never do nothing\n2      ham  now u sound like manky scouse boy steve,like! ...\n3      ham  mum say we wan to go then go... then she can s...\n4      ham  never y lei... i v lazy... got wat? dat day ü ...\n...    ...                                                ...\n4174   ham  just woke up. yeesh its late. but i didn't fal...\n4175   ham  what do u reckon as need 2 arrange transport i...\n4176  spam  free entry into our £250 weekly competition ju...\n4177  spam  -pls stop bootydelious (32/f) is inviting you ...\n4178   ham  tell my  bad character which u dnt lik in me. ...\n\n[4179 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>ahhhh...just woken up!had a bad dream about u ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>you can never do nothing</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>now u sound like manky scouse boy steve,like! ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>mum say we wan to go then go... then she can s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>never y lei... i v lazy... got wat? dat day ü ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4174</th>\n      <td>ham</td>\n      <td>just woke up. yeesh its late. but i didn't fal...</td>\n    </tr>\n    <tr>\n      <th>4175</th>\n      <td>ham</td>\n      <td>what do u reckon as need 2 arrange transport i...</td>\n    </tr>\n    <tr>\n      <th>4176</th>\n      <td>spam</td>\n      <td>free entry into our £250 weekly competition ju...</td>\n    </tr>\n    <tr>\n      <th>4177</th>\n      <td>spam</td>\n      <td>-pls stop bootydelious (32/f) is inviting you ...</td>\n    </tr>\n    <tr>\n      <th>4178</th>\n      <td>ham</td>\n      <td>tell my  bad character which u dnt lik in me. ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>4179 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"test_file = pd.read_csv(test_file_path, sep='\\t', names=names)\ntest_file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:42:07.559303Z","iopub.execute_input":"2024-12-27T04:42:07.559599Z","iopub.status.idle":"2024-12-27T04:42:07.572120Z","shell.execute_reply.started":"2024-12-27T04:42:07.559571Z","shell.execute_reply":"2024-12-27T04:42:07.571330Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     class                                            message\n0      ham  i am in hospital da. . i will return home in e...\n1      ham         not much, just some textin'. how bout you?\n2      ham  i probably won't eat at all today. i think i'm...\n3      ham  don‘t give a flying monkeys wot they think and...\n4      ham                                who are you seeing?\n...    ...                                                ...\n1387   ham  true dear..i sat to pray evening and felt so.s...\n1388   ham               what will we do in the shower, baby?\n1389   ham  where are you ? what are you doing ? are yuou ...\n1390  spam  ur cash-balance is currently 500 pounds - to m...\n1391  spam  not heard from u4 a while. call 4 rude chat pr...\n\n[1392 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>i am in hospital da. . i will return home in e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>not much, just some textin'. how bout you?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>i probably won't eat at all today. i think i'm...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>don‘t give a flying monkeys wot they think and...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>who are you seeing?</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1387</th>\n      <td>ham</td>\n      <td>true dear..i sat to pray evening and felt so.s...</td>\n    </tr>\n    <tr>\n      <th>1388</th>\n      <td>ham</td>\n      <td>what will we do in the shower, baby?</td>\n    </tr>\n    <tr>\n      <th>1389</th>\n      <td>ham</td>\n      <td>where are you ? what are you doing ? are yuou ...</td>\n    </tr>\n    <tr>\n      <th>1390</th>\n      <td>spam</td>\n      <td>ur cash-balance is currently 500 pounds - to m...</td>\n    </tr>\n    <tr>\n      <th>1391</th>\n      <td>spam</td>\n      <td>not heard from u4 a while. call 4 rude chat pr...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1392 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_message = train_file[\"message\"].values.tolist()\ntrain_label = np.array([0 if x==\"ham\" else 1 for x in train_file['class'].values.tolist()])\ntest_message = test_file[\"message\"].values.tolist()\ntest_label = np.array([0 if x==\"ham\" else 1 for x in test_file['class'].values.tolist()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:42:07.572772Z","iopub.execute_input":"2024-12-27T04:42:07.573056Z","iopub.status.idle":"2024-12-27T04:42:07.580365Z","shell.execute_reply.started":"2024-12-27T04:42:07.573025Z","shell.execute_reply":"2024-12-27T04:42:07.579526Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"vocabulary_dict = {}\nfor messgae in train_message:\n  for vocabulary in messgae.split():\n    if vocabulary not in vocabulary_dict:\n      vocabulary_dict[vocabulary] = 1\n    else:\n      vocabulary_dict[vocabulary] += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:42:07.582408Z","iopub.execute_input":"2024-12-27T04:42:07.582652Z","iopub.status.idle":"2024-12-27T04:42:07.614130Z","shell.execute_reply.started":"2024-12-27T04:42:07.582627Z","shell.execute_reply":"2024-12-27T04:42:07.613254Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"VOCAB_SIZE = len(vocabulary_dict)\nMAX_LENGTH = len(max(train_message, key=lambda p: len(p.split())).split())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:42:07.615598Z","iopub.execute_input":"2024-12-27T04:42:07.615815Z","iopub.status.idle":"2024-12-27T04:42:07.636424Z","shell.execute_reply.started":"2024-12-27T04:42:07.615782Z","shell.execute_reply":"2024-12-27T04:42:07.635860Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\nencoded_train_message = [one_hot(d, VOCAB_SIZE) for d in train_message]\npadded_train_message = pad_sequences(encoded_train_message, maxlen=MAX_LENGTH, padding='post')\nencoded_test_message = [one_hot(d, VOCAB_SIZE) for d in test_message]\npadded_test_message = pad_sequences(encoded_test_message, maxlen=MAX_LENGTH, padding='post')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:42:07.637211Z","iopub.execute_input":"2024-12-27T04:42:07.637408Z","iopub.status.idle":"2024-12-27T04:42:07.756398Z","shell.execute_reply.started":"2024-12-27T04:42:07.637381Z","shell.execute_reply":"2024-12-27T04:42:07.755815Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Flatten, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nmodel = Sequential()\nembedding_layer = Embedding(VOCAB_SIZE, 100, input_length=MAX_LENGTH)\nmodel.add(embedding_layer)\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',  \n    patience=5,          \n    restore_best_weights=True  \n)\n\nmodel.fit(\n    padded_train_message, \n    train_label, \n    validation_data=(padded_test_message, test_label), \n    epochs=100, \n    verbose=2, \n    callbacks=[early_stopping]  \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:56:20.811011Z","iopub.execute_input":"2024-12-27T04:56:20.811307Z","iopub.status.idle":"2024-12-27T04:56:30.670181Z","shell.execute_reply.started":"2024-12-27T04:56:20.811287Z","shell.execute_reply":"2024-12-27T04:56:30.669400Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n131/131 - 2s - 13ms/step - acc: 0.9174 - loss: 0.2275 - val_acc: 0.9749 - val_loss: 0.0935\nEpoch 2/100\n131/131 - 1s - 7ms/step - acc: 0.9854 - loss: 0.0560 - val_acc: 0.9820 - val_loss: 0.0561\nEpoch 3/100\n131/131 - 1s - 7ms/step - acc: 0.9914 - loss: 0.0279 - val_acc: 0.9842 - val_loss: 0.0469\nEpoch 4/100\n131/131 - 1s - 7ms/step - acc: 0.9957 - loss: 0.0146 - val_acc: 0.9856 - val_loss: 0.0476\nEpoch 5/100\n131/131 - 1s - 7ms/step - acc: 0.9981 - loss: 0.0084 - val_acc: 0.9892 - val_loss: 0.0394\nEpoch 6/100\n131/131 - 1s - 7ms/step - acc: 0.9993 - loss: 0.0054 - val_acc: 0.9892 - val_loss: 0.0394\nEpoch 7/100\n131/131 - 1s - 7ms/step - acc: 0.9998 - loss: 0.0038 - val_acc: 0.9892 - val_loss: 0.0400\nEpoch 8/100\n131/131 - 1s - 7ms/step - acc: 0.9998 - loss: 0.0028 - val_acc: 0.9878 - val_loss: 0.0432\nEpoch 9/100\n131/131 - 1s - 7ms/step - acc: 0.9998 - loss: 0.0023 - val_acc: 0.9892 - val_loss: 0.0406\nEpoch 10/100\n131/131 - 1s - 7ms/step - acc: 0.9998 - loss: 0.0017 - val_acc: 0.9885 - val_loss: 0.0428\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c01fc4eab90>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# function to predict messages based on model\n# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\ndef predict_message(pred_text):\n  class_dict = {\n      0 : \"ham\",\n      1 : \"spam\",\n      }\n  encoded_message = [one_hot(pred_text, VOCAB_SIZE)]\n  padded_message = pad_sequences(encoded_message, maxlen=MAX_LENGTH, padding='post')\n  prediction = [model.predict(padded_message)[0][0], class_dict[np.round(model.predict(padded_message)[0][0])]]\n  return prediction\n\npred_text = \"how are you doing today?\"\n\nprediction = predict_message(pred_text)\nprint(prediction)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:56:35.372038Z","iopub.execute_input":"2024-12-27T04:56:35.372367Z","iopub.status.idle":"2024-12-27T04:56:35.528482Z","shell.execute_reply.started":"2024-12-27T04:56:35.372343Z","shell.execute_reply":"2024-12-27T04:56:35.527735Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n[0.0022614305, 'ham']\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Run this cell to test your function and model. Do not modify contents.\ndef test_predictions():\n  test_messages = [\"how are you doing today\",\n                   \"sale today! to stop texts call 98912460324\",\n                   \"i dont want to go. can we try it a different day? available sat\",\n                   \"our new mobile video service is live. just install on your phone to start watching.\",\n                   \"you have won £1000 cash! call to claim your prize.\",\n                   \"i'll bring it tomorrow. don't forget the milk.\",\n                   \"wow, is your arm alright. that happened to me one time too\"\n                  ]\n\n  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n  passed = True\n\n  for msg, ans in zip(test_messages, test_answers):\n    prediction = predict_message(msg)\n    if prediction[1] != ans:\n      passed = False\n\n  if passed:\n    print(\"You passed the challenge. Great job!\")\n  else:\n    print(\"You haven't passed yet. Keep trying.\")\n\ntest_predictions()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T04:56:37.551548Z","iopub.execute_input":"2024-12-27T04:56:37.551891Z","iopub.status.idle":"2024-12-27T04:56:38.369472Z","shell.execute_reply.started":"2024-12-27T04:56:37.551863Z","shell.execute_reply":"2024-12-27T04:56:38.368458Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nYou passed the challenge. Great job!\n","output_type":"stream"}],"execution_count":28}]}